---
title: "2025年应该怎么用大模型"
description: "# 2025年应该怎么用大模型 2025年了，模型能力上升了一个台阶，更不需要去记提示词技巧和框架了，写提示词 [&hellip;]"
pubDate: "Jul 19, 2025"
tags: ["技术"]
heroImage: '../../assets/tech1.png'
---

\# 2025年应该怎么用大模型

2025年了，模型能力上升了一个台阶，更不需要去记提示词技巧和框架了，写提示词不再是一个多专业的活，核心就记住三点半：

\## 核心要点

1\. \*\*Context(上下文)\*\*：  
\- 问题所需要的上下文信息，千万别以为模型会读心术，一定要把相关信息都提供  
\- 长度不要太长，因为长度越长效果越差  
\- 不同模型对长度要求有区别，多试试就知道了

2\. \*\*Instruction(指令)\*\*：  
\- 你想要模型做什么要说清楚  
\- 如果自己都没想清楚，就先临时开个会话和模型闲聊  
\- 让它帮你梳理清楚后，再新开会话输入你的指令和上下文

3\. \*\*Atom(原子化)\*\*：  
\- 每次的任务要小，不要想让模型一次完成太多任务  
\- 上下文要完整独立，在你的会话中把这次任务的上下文都提供清楚

4\. \*\*CoT(思维链)\*\*：  
\- Chain of Thought对于大语言模型来说已经慢慢成了基本技能  
\- 尤其是推理模型，已高于人类平均水平  
\- 如果你明确知道最优步骤，就写上  
\- 不确定就让模型写，不满意就让模型改进  
\- 还不满意就新开会话或者换模型再试试

\## 上下文完整性说明

上下文完整独立的意思就是在一次会话中，你包含了AI生成所需要的完整内容，并且确保不会因为AI应用程序的能力限制而影响。

以写报告为例：  
\- 如果报告中需要参考资料1、2、3，这些参考资料的完整部分或者关键部分要在会话中完整包含  
\- 如果参考资料是URL，由于ChatGPT等应用无法访问URL，就无法有效把URL作为上下文的一部分  
\- 如果在前几轮会话中放了参考资料，持续问答增加会话后，AI可能会因为上下文窗口长度限制而自动截断前面的内容

判断独立完整的标准：你的提示词放到任何模型任何AI应用，信息都是完整的，不会因为AI应用的能力限制而导致内容缺失。

\## 实用技巧分享

为了保持对话不被污染，我的做法是：

1\. 保持主对话过程极其单一  
2\. 另外开1-2个旁支对话窗口用来问相关问题  
3\. 问清楚后，用简洁、明确的问题，把旁支问题转进主对话

这种方法虽然会丢失一些上下文，但避免了主对话里掺杂太多相关问题、次要问题甚至有误导的问题。

这种AI提问技巧，其实来自于客户咨询设计的经验：我们不会一根筋只聊"某某某怎么设计"，还会聊生意、用户、执行等等，话题涵盖了深度和广度。这种交流也需要避免话题污染，不管说到多远、多深，都要做好"主持人"，把交流拽回到主要话题上。